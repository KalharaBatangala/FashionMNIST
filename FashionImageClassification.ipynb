{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmme8gaOyVgTZxkwsFY2k9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KalharaBatangala/FashionMNIST/blob/main/FashionImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4W4elxSA-SE-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from PIL import Image   # just import only class Image\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening destroys locality\n",
        "<br>Convolutions preserve it"
      ],
      "metadata": {
        "id": "HCMh-HiHNWOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert PIL images to pytorch tensors\n",
        "transforms = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "_VtwTbvrN0UZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train dataset\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n",
        "\n",
        "# no of training exmples\n",
        "print(f'Number of training examples {len(train_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtMUqjqKOHW_",
        "outputId": "832b297d-dd54-469e-c260-68979ed52ecc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 16.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 305kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.62MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 25.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples 60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]  # take one training exmple\n",
        "\n",
        "print(image.shape)  # [1,28,28] (C, H, W) because it is a pytorch tensor\n",
        "img_2d = image.squeeze()  # remove channel dimension\n",
        "print(img_2d.shape) # now (H, W)\n",
        "plt.imshow(img_2d, cmap='gray')  # it work with matplotlib\n",
        "plt.title(f\"Label : {label}\")\n",
        "plt.axis(\"off\")\n",
        "# matplotlib expects ---> (H, W) for grayscale and (H, W, C) for color\n",
        "# pytorch returns ---> (C, H, W) but this is different in tensorflow. Channel last"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "3MQ6YJh2R1cf",
        "outputId": "b0cff6e7-56de-4c29-b6c2-d6eb2d062ce0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(-0.5), np.float64(27.5), np.float64(27.5), np.float64(-0.5))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in pytorch, channel is the first value <br>\n",
        "torch.Size([1,28,28]) only 1 channel"
      ],
      "metadata": {
        "id": "lIw20BEzSzX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load test dataset\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms\n",
        ")\n"
      ],
      "metadata": {
        "id": "tQt3lY1x8tOL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of test examples {len(test_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkdfy09a9Wza",
        "outputId": "d65488f3-011f-4ad3-8836-66f1c4b2dec2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test examples 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "7qMqeTDs94GQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "40IwVTaM9-sP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect one batch\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(\"Batch image shape:\", images.shape)\n",
        "print(\"Batch labels shape:\", labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52QeeRbZ_Hnf",
        "outputId": "2d4bfe2b-4f18-4611-cc34-06f4ba815017"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch image shape: torch.Size([64, 1, 28, 28])\n",
            "Batch labels shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "jqNX3gfyBzNd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional block - 1**"
      ],
      "metadata": {
        "id": "H_6X1dMA6luO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer = nn.Conv2d(\n",
        "    in_channels=1,\n",
        "    out_channels=32,\n",
        "    kernel_size=3,\n",
        "    stride=1,\n",
        "    padding=1   # keep spatial size\n",
        ")\n",
        "\n",
        "relu = nn.ReLU()\n",
        "pool = nn.MaxPool2d(\n",
        "    kernel_size=2,    # half the size\n",
        "    stride=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "CpWbmua8CNgr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a feature extractor. Next we want a classifier, <br>\n",
        "that means a fully connected layer"
      ],
      "metadata": {
        "id": "r4ajr7GV7ChV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass one batch through the block\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "x = conv_layer(images)\n",
        "x = relu(x)\n",
        "x = pool(x)\n",
        "\n",
        "print(\"After Conv:\", conv_layer(images).shape)\n",
        "print(\"After ReLU:\", relu(conv_layer(images)).shape)\n",
        "print(\"After Pool:\", x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ0tnIonCusK",
        "outputId": "ae28af7a-8aba-40e4-e18d-7c2a1c17bfec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Conv: torch.Size([64, 32, 28, 28])\n",
            "After ReLU: torch.Size([64, 32, 28, 28])\n",
            "After Pool: torch.Size([64, 32, 14, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.Size([64, 32, 28, 28]) <br>\n",
        "this always follows the pytorch's convention (N, C, H, W)\n",
        "<br>\n",
        "64 = batch size (N) meaning 64 different stacks of\n",
        "<br> 32 feature maps"
      ],
      "metadata": {
        "id": "N3aE7a_YLI0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNNs do NOT detect objects <br> <br>\n",
        "They detect **features**"
      ],
      "metadata": {
        "id": "UyrnO7SJDKQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classifier**"
      ],
      "metadata": {
        "id": "Ln99pLZe8iwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fc = nn.Linear(32 * 14 * 14, 10)  # 10 classes in fashionMNIST\n",
        "\n",
        "# Forward pass continued\n",
        "x = x.view(x.size(0), -1)  # Flatten\n",
        "\n",
        "print(\"After flatten:\", x.shape)\n",
        "\n",
        "x = fc(x)\n",
        "\n",
        "print(\"After Linear:\", x.shape)   # gives 10 output logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfmUEExmDSHE",
        "outputId": "92101395-0047-4c13-afca-9e00c1c4c39e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After flatten: torch.Size([64, 6272])\n",
            "After Linear: torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logits = raw, unnormalized scores produced by the model"
      ],
      "metadata": {
        "id": "OnDm7IASTGqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGMSxzuCSmyn",
        "outputId": "9644e757-7a7b-40e2-f5c4-5b3ad65a54d7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    }
  ]
}